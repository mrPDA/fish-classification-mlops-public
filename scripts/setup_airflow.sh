#!/bin/bash

# ========================================
# üå¨Ô∏è  Airflow Setup Script
# ========================================
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ Airflow: –∑–∞–≥—Ä—É–∑–∫–∞ DAG –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö

set -e

# –¶–≤–µ—Ç–∞
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

echo -e "${BLUE}üå¨Ô∏è  –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Airflow...${NC}"

# ========================================
# –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Terraform
# ========================================

cd terraform 2>/dev/null || cd ../terraform 2>/dev/null || {
    echo -e "${RED}‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞ terraform${NC}"
    exit 1
}

# –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ Terraform
CLOUD_ID=$(terraform output -raw cloud_id 2>/dev/null || echo "")
FOLDER_ID=$(terraform output -raw folder_id 2>/dev/null || echo "")
ZONE=$(terraform output -raw zone 2>/dev/null || echo "ru-central1-a")
NETWORK_ID=$(terraform output -raw network_id 2>/dev/null || echo "")
SUBNET_ID=$(terraform output -raw subnet_id 2>/dev/null || echo "")
SECURITY_GROUP_ID=$(terraform output -raw security_group_id 2>/dev/null || echo "")
S3_BUCKET=$(terraform output -raw s3_bucket_name 2>/dev/null)
S3_ACCESS_KEY=$(terraform output -raw s3_access_key 2>/dev/null)
S3_SECRET_KEY=$(terraform output -raw s3_secret_key 2>/dev/null)
MLFLOW_IP=$(terraform output -raw mlflow_vm_ip 2>/dev/null)
DATAPROC_SA_ID=$(terraform output -raw dataproc_sa_id 2>/dev/null || echo "")
AIRFLOW_CLUSTER_ID=$(terraform output -raw airflow_cluster_id 2>/dev/null || echo "")

# –ü–æ–ª—É—á–∞–µ–º SSH –∫–ª—é—á
if [ -f "../ssh_keys/dataproc.pub" ]; then
    SSH_KEY=$(cat ../ssh_keys/dataproc.pub)
elif [ -f ~/.ssh/id_rsa.pub ]; then
    SSH_KEY=$(cat ~/.ssh/id_rsa.pub)
else
    SSH_KEY="ssh-rsa PLACEHOLDER_SSH_KEY"
    echo -e "${YELLOW}‚ö†Ô∏è  SSH –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è placeholder${NC}"
fi

# –ü–æ–ª—É—á–∞–µ–º Service Account JSON
SA_JSON_FILE="sa-key.json"
if [ -f "$SA_JSON_FILE" ]; then
    SA_JSON=$(cat "$SA_JSON_FILE" | jq -c .)
    echo -e "${GREEN}‚úÖ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª service account: $SA_JSON_FILE${NC}"
elif [ -f "../$SA_JSON_FILE" ]; then
    SA_JSON=$(cat "../$SA_JSON_FILE" | jq -c .)
    echo -e "${GREEN}‚úÖ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª service account: ../$SA_JSON_FILE${NC}"
else
    echo -e "${YELLOW}‚ö†Ô∏è  –§–∞–π–ª service account –Ω–µ –Ω–∞–π–¥–µ–Ω: $SA_JSON_FILE${NC}"
    SA_JSON='{"type": "service_account", "service_account_id": "'$DATAPROC_SA_ID'"}'
fi

if [ -z "$S3_BUCKET" ]; then
    echo -e "${RED}‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ Terraform${NC}"
    echo -e "${YELLOW}–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ terraform apply –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ${NC}"
    exit 1
fi

cd ..

echo -e "${GREEN}‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã:${NC}"
echo -e "  Cloud ID: $CLOUD_ID"
echo -e "  Folder ID: $FOLDER_ID"
echo -e "  Zone: $ZONE"
echo -e "  Network ID: $NETWORK_ID"
echo -e "  Subnet ID: $SUBNET_ID"
echo -e "  Security Group ID: $SECURITY_GROUP_ID"
echo -e "  S3 Bucket: $S3_BUCKET"
echo -e "  MLflow IP: $MLFLOW_IP"
echo -e "  DataProc SA ID: $DATAPROC_SA_ID"
if [ ! -z "$AIRFLOW_CLUSTER_ID" ]; then
    echo -e "  Airflow Cluster: $AIRFLOW_CLUSTER_ID"
fi

# ========================================
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö Airflow
# ========================================

echo -e "${BLUE}üìù –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö...${NC}"

# –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
cat airflow/variables.json | \
    sed "s|{{ CLOUD_ID }}|$CLOUD_ID|g" | \
    sed "s|{{ FOLDER_ID }}|$FOLDER_ID|g" | \
    sed "s|{{ ZONE }}|$ZONE|g" | \
    sed "s|{{ NETWORK_ID }}|$NETWORK_ID|g" | \
    sed "s|{{ SUBNET_ID }}|$SUBNET_ID|g" | \
    sed "s|{{ SECURITY_GROUP_ID }}|$SECURITY_GROUP_ID|g" | \
    sed "s|{{ S3_BUCKET_NAME }}|$S3_BUCKET|g" | \
    sed "s|{{ S3_ACCESS_KEY }}|$S3_ACCESS_KEY|g" | \
    sed "s|{{ S3_SECRET_KEY }}|$S3_SECRET_KEY|g" | \
    sed "s|{{ DATAPROC_SERVICE_ACCOUNT_ID }}|$DATAPROC_SA_ID|g" | \
    sed "s|{{ MLFLOW_IP }}|$MLFLOW_IP|g" \
    > /tmp/airflow_variables_temp.json

# –ó–∞–º–µ–Ω—è–µ–º DP_SA_JSON –∏ YC_SSH_PUBLIC_KEY —á–µ—Ä–µ–∑ jq (—Ç.–∫. –æ–Ω–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã)
jq --arg sa_json "$SA_JSON" --arg ssh_key "$SSH_KEY" \
    '.DP_SA_JSON = $sa_json | .YC_SSH_PUBLIC_KEY = $ssh_key' \
    /tmp/airflow_variables_temp.json > /tmp/airflow_variables.json

rm -f /tmp/airflow_variables_temp.json

echo -e "${GREEN}‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã${NC}"

# ========================================
# –ó–∞–≥—Ä—É–∑–∫–∞ DAG –∏ —Å–∫—Ä–∏–ø—Ç–æ–≤ –≤ S3 (–¥–ª—è Managed Airflow)
# ========================================

echo -e "${BLUE}üì§ –ó–∞–≥—Ä—É–∑–∫–∞ DAG –∏ —Å–∫—Ä–∏–ø—Ç–æ–≤ –≤ S3...${NC}"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏
upload_directory() {
    local source_dir=$1
    local s3_prefix=$2
    local file_count=0
    
    if [ -d "$source_dir" ]; then
        echo -e "${YELLOW}üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ $source_dir...${NC}"
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ Python —Ñ–∞–π–ª—ã –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        while IFS= read -r file; do
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç source_dir
            relative_path="${file#$source_dir/}"
            s3_path="s3://$S3_BUCKET/$s3_prefix/$relative_path"
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
            if yc storage s3 cp "$file" "$s3_path" 2>/dev/null; then
                echo -e "${GREEN}  ‚úÖ $relative_path${NC}"
                ((file_count++))
            else
                echo -e "${RED}  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ $relative_path${NC}"
            fi
        done < <(find "$source_dir" -type f \( -name "*.py" -o -name "*.txt" -o -name "*.yaml" -o -name "*.yml" \))
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã (—Ç.–∫. –≤ subshell –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è)
        local uploaded=$(find "$source_dir" -type f \( -name "*.py" -o -name "*.txt" -o -name "*.yaml" -o -name "*.yml" \) | wc -l | tr -d ' ')
        echo -e "${GREEN}  ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: $uploaded${NC}"
    else
        echo -e "${YELLOW}  ‚ö†Ô∏è  –ü–∞–ø–∫–∞ $source_dir –Ω–µ –Ω–∞–π–¥–µ–Ω–∞${NC}"
    fi
    return 0  # Ensure successful exit
}

# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ DAG —Ñ–∞–π–ª—ã
upload_directory "dags" "airflow-dags"

# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ Spark —Å–∫—Ä–∏–ø—Ç—ã
upload_directory "spark_jobs" "spark_jobs"

# –¢–∞–∫–∂–µ –∑–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ä—É—é –ø–∞–ø–∫—É spark, –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
if [ -d "spark" ]; then
    upload_directory "spark" "scripts"
fi

# –ó–∞–≥—Ä—É–∂–∞–µ–º requirements, –µ—Å–ª–∏ –µ—Å—Ç—å
if [ -f "training/requirements.txt" ]; then
    echo -e "${YELLOW}üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ training requirements...${NC}"
    if yc storage s3 cp training/requirements.txt \
        "s3://$S3_BUCKET/airflow-dags/requirements.txt" 2>/dev/null; then
        echo -e "${GREEN}  ‚úÖ training/requirements.txt${NC}"
    fi
fi

if [ -f "requirements.txt" ]; then
    echo -e "${YELLOW}üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ requirements...${NC}"
    if yc storage s3 cp requirements.txt \
        "s3://$S3_BUCKET/airflow-dags/requirements.txt" 2>/dev/null; then
        echo -e "${GREEN}  ‚úÖ requirements.txt${NC}"
    fi
fi

echo -e "${GREEN}‚úÖ DAG –∏ —Å–∫—Ä–∏–ø—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ S3${NC}"

# ========================================
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ Airflow CLI/API
# ========================================

echo -e "${BLUE}üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ Airflow...${NC}"

# –ú–µ—Ç–æ–¥ 1: –ß–µ—Ä–µ–∑ Airflow REST API (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
AIRFLOW_URL=$(cd terraform && terraform output -raw airflow_webserver_url 2>/dev/null | sed 's|https://||' || echo "") || true

if [ ! -z "$AIRFLOW_URL" ]; then
    echo -e "${YELLOW}Airflow URL: https://$AIRFLOW_URL${NC}"
    
    # –ü–æ–ª—É—á–∞–µ–º admin password
    AIRFLOW_PASSWORD=$(cd terraform && terraform output -raw airflow_admin_password 2>/dev/null || echo "")
    
    if [ ! -z "$AIRFLOW_PASSWORD" ]; then
        echo -e "${YELLOW}–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ API...${NC}"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–∂–¥—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        while IFS= read -r line; do
            if echo "$line" | grep -q ":"; then
                key=$(echo "$line" | sed 's/.*"\(.*\)".*/\1/' | sed 's/:.*//')
                value=$(echo "$line" | sed 's/.*: "\(.*\)".*/\1/' | sed 's/",*//')
                
                if [ ! -z "$key" ] && [ ! -z "$value" ]; then
                    curl -X POST "https://$AIRFLOW_URL/api/v1/variables" \
                        -H "Content-Type: application/json" \
                        -u "admin:$AIRFLOW_PASSWORD" \
                        -d "{\"key\": \"$key\", \"value\": \"$value\"}" \
                        --insecure -s -o /dev/null || true
                fi
            fi
        done < /tmp/airflow_variables.json
        
        echo -e "${GREEN}‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —á–µ—Ä–µ–∑ API${NC}"
    fi
fi

# ========================================
# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥: –ß–µ—Ä–µ–∑ yc CLI
# ========================================

echo -e "${BLUE}üìã –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥: yc CLI...${NC}"

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ ConfigMap –∫–ª–∞—Å—Ç–µ—Ä–∞
cat > /tmp/airflow_env.yaml << EOF
# Airflow Environment Variables
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –≤—Ä—É—á–Ω—É—é —á–µ—Ä–µ–∑ Airflow UI: Admin -> Variables -> Import
$(cat /tmp/airflow_variables.json)
EOF

echo -e "${YELLOW}–§–∞–π–ª —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: /tmp/airflow_env.yaml${NC}"
echo -e "${YELLOW}–î–ª—è —Ä—É—á–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞:${NC}"
echo -e "  1. –û—Ç–∫—Ä–æ–π—Ç–µ Airflow UI: https://$AIRFLOW_URL"
echo -e "  2. Admin -> Variables -> Import"
echo -e "  3. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª: /tmp/airflow_variables.json"

# ========================================
# –ü—Ä–æ–≤–µ—Ä–∫–∞ DAG –≤ S3
# ========================================

echo -e "${BLUE}üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...${NC}"

echo -e "${YELLOW}DAGs –≤ S3:${NC}"
yc storage s3api list-objects --bucket "$S3_BUCKET" --prefix "airflow-dags/" 2>/dev/null | \
    grep "key:" | sed 's/.*key: /  /' || echo "  (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ yc storage s3api –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)" || true

# ========================================
# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è —Ä—É—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
# ========================================

echo ""
echo -e "${GREEN}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó${NC}"
echo -e "${GREEN}‚ïë  ‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Airflow –∑–∞–≤–µ—Ä—à–µ–Ω–∞!      ‚ïë${NC}"
echo -e "${GREEN}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù${NC}"
echo ""

echo -e "${BLUE}üìã –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:${NC}"
echo ""
echo -e "${YELLOW}1. –û—Ç–∫—Ä–æ–π—Ç–µ Airflow UI:${NC}"
echo -e "   https://$AIRFLOW_URL"
echo -e "   –õ–æ–≥–∏–Ω: admin"
echo -e "   –ü–∞—Ä–æ–ª—å: (–∏–∑ terraform.tfvars)"
echo ""
echo -e "${YELLOW}2. –ò–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–µ—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏):${NC}"
echo -e "   Admin -> Variables -> Import Variables"
echo -e "   –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª: /tmp/airflow_variables.json"
echo ""
echo -e "${YELLOW}3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ DAG:${NC}"
echo -e "   DAGs -> fish_classification_training"
echo -e "   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ DAG –∑–∞–≥—Ä—É–∂–µ–Ω –±–µ–∑ –æ—à–∏–±–æ–∫"
echo ""
echo -e "${YELLOW}4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ:${NC}"
echo -e "   –ù–∞–∂–º–∏—Ç–µ –Ω–∞ DAG -> Trigger DAG"
echo ""

# Cleanup
rm -f /tmp/airflow_variables.json /tmp/airflow_env.yaml

echo -e "${GREEN}‚ú® –ì–æ—Ç–æ–≤–æ!${NC}"
echo ""

# Ensure successful exit
exit 0
