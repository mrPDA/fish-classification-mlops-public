# â˜¸ï¸ Kubernetes + Managed Services - ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½Ğ°

## ğŸ¯ Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         YANDEX CLOUD                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MANAGED SERVICES       â”‚  â”‚         KUBERNETES                   â”‚
â”‚   (Managed by Yandex)    â”‚  â”‚      (Your workloads)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                          â”‚  â”‚                                      â”‚
â”‚  ğŸŒŠ Airflow              â”‚  â”‚  Namespace: ml-inference             â”‚
â”‚     â€¢ Orchestration      â”‚â—„â”€â”¤  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚     â€¢ DAG scheduling     â”‚  â”‚  â”‚ ğŸŒ Inference API (FastAPI)    â”‚ â”‚
â”‚     â€¢ DataProc control   â”‚  â”‚  â”‚    â€¢ 3-20 replicas            â”‚ â”‚
â”‚                          â”‚  â”‚  â”‚    â€¢ HPA (CPU-based)          â”‚ â”‚
â”‚  ğŸ¤– MLflow (VM)          â”‚  â”‚  â”‚    â€¢ LoadBalancer service     â”‚ â”‚
â”‚     â€¢ Tracking server    â”‚â—„â”€â”¤  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚     â€¢ Model registry     â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚     â€¢ Artifact storage   â”‚  â”‚  â”‚ ğŸ‘· ML Workers                 â”‚ â”‚
â”‚                          â”‚  â”‚  â”‚    â€¢ 2-10 replicas            â”‚ â”‚
â”‚  ğŸ—„ï¸  PostgreSQL          â”‚  â”‚  â”‚    â€¢ Kafka consumers          â”‚ â”‚
â”‚     â€¢ Airflow metadata   â”‚  â”‚  â”‚    â€¢ Batch processing         â”‚ â”‚
â”‚     â€¢ MLflow backend     â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  ğŸ“¨ Kafka â­             â”‚â—„â”€â”¤  â”‚ ğŸš€ Redis                      â”‚ â”‚
â”‚     â€¢ 1 broker           â”‚  â”‚  â”‚    â€¢ 1 replica                â”‚ â”‚
â”‚     â€¢ Topics:            â”‚  â”‚  â”‚    â€¢ Caching                  â”‚ â”‚
â”‚       - requests         â”‚  â”‚  â”‚    â€¢ Status tracking          â”‚ â”‚
â”‚       - results          â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚     â€¢ s2.micro (2vCPU)   â”‚  â”‚                                      â”‚
â”‚     â€¢ 32GB HDD           â”‚  â”‚  ğŸ“Š Monitoring (optional)            â”‚
â”‚                          â”‚  â”‚     â€¢ Prometheus                     â”‚
â”‚  ğŸ”¥ DataProc             â”‚  â”‚     â€¢ Node exporters                 â”‚
â”‚     â€¢ On-demand clusters â”‚  â”‚                                      â”‚
â”‚     â€¢ Spark + GPU        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚     â€¢ Auto-termination   â”‚              â–²
â”‚                          â”‚              â”‚
â”‚  ğŸ“Š Grafana (VM)         â”‚              â”‚
â”‚     â€¢ Monitoring         â”‚         LoadBalancer
â”‚     â€¢ Dashboards         â”‚         (External IP)
â”‚                          â”‚              â”‚
â”‚  â˜ï¸  S3 Storage          â”‚              â”‚
â”‚     â€¢ Datasets           â”‚              â”‚
â”‚     â€¢ Models             â”‚              â–¼
â”‚     â€¢ Artifacts          â”‚         ğŸ‘¥ Users
â”‚     â€¢ Kafka data         â”‚         (API Clients)
â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Ğ§Ñ‚Ğ¾ Ğ³Ğ´Ğµ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ğ¾

### âœ… MANAGED SERVICES (Yandex Cloud)

#### 1. **Apache Airflow**
```
Type:       Managed Service for Apache Airflow
Purpose:    Orchestration ML pipeline
Version:    2.9.x
Resources:  2 vCPU, 8 GB RAM (s2.medium)
Features:
  â€¢ DAG scheduling
  â€¢ DataProc cluster creation
  â€¢ Lockbox secrets integration
  â€¢ S3 integration for DAGs
```

#### 2. **PostgreSQL**
```
Type:       Managed Service for PostgreSQL
Purpose:    Metadata storage
Version:    14
Resources:  2 vCPU, 8 GB RAM (s2.medium)
Databases:
  â€¢ airflow - Airflow metadata
  â€¢ mlflow - MLflow backend (optional)
Features:
  â€¢ Automatic backups
  â€¢ High availability
  â€¢ Connection pooling (PgBouncer)
```

#### 3. **Kafka** â­
```
Type:       Managed Service for Apache Kafka
Purpose:    Message queue for batch processing
Version:    3.6
Brokers:    1
Resources:  s2.micro (2 vCPU, 8 GB RAM)
Disk:       32 GB HDD
Connection: rc1a-mjs21l34cb7dh25g.mdb.yandexcloud.net:9091
Auth:       SASL_SSL

Pre-created Topics:
  â€¢ fish-classification-requests (3 partitions, 1 replication)
  â€¢ fish-classification-results (3 partitions, 1 replication)

Config:
  â€¢ Compression: GZIP
  â€¢ Retention: 7 days
  â€¢ Retention size: 1 GB per topic
```

#### 4. **MLflow** (VM)
```
Type:       Compute Instance (VM)
Purpose:    Experiment tracking & model registry
Resources:  2 vCPU, 4 GB RAM
OS:         Ubuntu 22.04
Services:
  â€¢ MLflow Server (port 5000)
  â€¢ PostgreSQL backend (optional)
  â€¢ S3 artifact storage
```

#### 5. **Grafana** (VM)
```
Type:       Compute Instance (VM)
Purpose:    Monitoring & visualization
Resources:  2 vCPU, 4 GB RAM
OS:         Ubuntu 22.04
Features:
  â€¢ Auto-installed via cloud-init
  â€¢ Pre-configured datasources (MLflow, PostgreSQL)
  â€¢ Dashboard provisioning
```

#### 6. **DataProc** (On-demand)
```
Type:       Managed Service for Apache Spark
Purpose:    Model training
Mode:       On-demand (created by Airflow, auto-terminated)
Resources:  s3-c4-m16 (4 vCPU, 16 GB RAM)
Features:
  â€¢ PySpark jobs
  â€¢ GPU support (optional)
  â€¢ S3 integration
  â€¢ MLflow logging
```

#### 7. **S3 Object Storage**
```
Type:       Object Storage
Purpose:    Data lake
Bucket:     fish-classification-data-<suffix>
Contents:
  â€¢ datasets/ - Fish images
  â€¢ models/ - Trained models
  â€¢ spark_jobs/ - PySpark scripts
  â€¢ airflow-dags/ - Airflow DAG files
  â€¢ mlflow-artifacts/ - MLflow artifacts
```

---

### â˜¸ï¸ KUBERNETES

#### K8s Cluster
```
Type:       Managed Kubernetes
Version:    1.28
Master:     Managed by Yandex
Nodes:      2Ã— s3-c2-m8 (2 vCPU, 8 GB RAM)
Network:    Internal subnet
```

#### Namespace: `ml-inference`

##### 1. **Inference API (FastAPI)**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fish-api
  namespace: ml-inference
spec:
  replicas: 3
  
  # HPA configuration
  minReplicas: 2
  maxReplicas: 20
  targetCPUUtilizationPercentage: 70
  
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2
      memory: 2Gi
  
  env:
  - name: MLFLOW_TRACKING_URI
    value: "http://51.250.15.131:5000"
  - name: REDIS_HOST
    value: "redis.ml-inference.svc.cluster.local"
  - name: KAFKA_BOOTSTRAP_SERVERS
    value: "rc1a-mjs21l34cb7dh25g.mdb.yandexcloud.net:9091"
  - name: KAFKA_USER
    value: "kafka_user"
  - name: KAFKA_PASSWORD
    valueFrom:
      secretKeyRef:
        name: kafka-credentials
        key: password
```

**Endpoints:**
- `POST /predict` - Real-time inference
- `POST /batch/predict` - Batch via Kafka
- `GET /batch/status/:id` - Batch status
- `GET /health` - Health check
- `GET /metrics` - Prometheus metrics

##### 2. **ML Workers**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-worker
  namespace: ml-inference
spec:
  replicas: 2
  
  # Scale based on Kafka lag
  minReplicas: 1
  maxReplicas: 10
  
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 4
      memory: 4Gi
  
  env:
  - name: KAFKA_BOOTSTRAP_SERVERS
    value: "rc1a-mjs21l34cb7dh25g.mdb.yandexcloud.net:9091"
  - name: KAFKA_TOPIC
    value: "fish-classification-requests"
  - name: KAFKA_GROUP_ID
    value: "ml-workers"
```

**Functions:**
- Read from Kafka (Managed Service)
- Load images from URLs
- Run inference
- Save results to S3
- Update status in Redis

##### 3. **Redis**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: ml-inference
spec:
  replicas: 1
  
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
```

**Usage:**
- Cache predictions (TTL: 1 hour)
- Store batch job statuses (TTL: 24 hours)
- Atomic operations

---

## ğŸ”„ Data Flow

### Training Pipeline (Managed Services):

```
1. Airflow DAG triggered (scheduled/manual)
   â”‚
2. Create DataProc cluster
   â”‚
3. Submit PySpark job
   â”‚
   â”œâ”€â†’ Read dataset from S3
   â”œâ”€â†’ Train model (TensorFlow)
   â”œâ”€â†’ Log to MLflow
   â””â”€â†’ Save model to S3
   â”‚
4. Terminate DataProc cluster
   â”‚
5. Verify results in MLflow
```

### Real-time Inference (K8s):

```
User â†’ LoadBalancer â†’ API Pod
                        â”‚
                        â”œâ”€â†’ Check Redis cache
                        â”‚   â”œâ”€ Hit: return cached result
                        â”‚   â””â”€ Miss: continue
                        â”‚
                        â”œâ”€â†’ Load model from S3 (via MLflow)
                        â”œâ”€â†’ Run inference
                        â”œâ”€â†’ Cache result in Redis
                        â””â”€â†’ Return prediction
```

### Batch Inference (K8s + Managed Kafka):

```
User â†’ API Pod
        â”‚
        â”œâ”€â†’ Generate request_id
        â”œâ”€â†’ Send to Managed Kafka â­
        â”œâ”€â†’ Set status in Redis: "queued"
        â””â”€â†’ Return {"request_id": "abc", "status": "queued"}

Managed Kafka â­
        â”‚
        â”œâ”€â†’ Store message (persistent)
        â””â”€â†’ Notify consumers

ML Worker Pod (K8s)
        â”‚
        â”œâ”€â†’ Read from Managed Kafka â­
        â”œâ”€â†’ Update Redis: "processing"
        â”œâ”€â†’ Load images
        â”œâ”€â†’ Run inference
        â”œâ”€â†’ Save to S3
        â””â”€â†’ Update Redis: "completed"

User â†’ API Pod â†’ Redis â†’ Return results
```

---

## ğŸ’° Cost Breakdown

| Component | Type | Resources | Cost/month |
|-----------|------|-----------|------------|
| **Managed Services** |||
| Airflow | Managed | s2.medium | ~5,000â‚½ |
| PostgreSQL | Managed | s2.medium | ~4,000â‚½ |
| **Kafka** â­ | **Managed** | **s2.micro + 32GB** | **~3,000â‚½** |
| MLflow VM | VM | s3-c2-m4 | ~1,500â‚½ |
| Grafana VM | VM | s3-c2-m4 | ~1,500â‚½ |
| S3 Storage | Object Storage | 100 GB | ~300â‚½ |
| **Kubernetes** |||
| K8s Master | Managed | - | ~1,500â‚½ |
| Worker Nodes | VM | 2Ã— s3-c2-m8 | ~6,000â‚½ |
| Load Balancer | Network | - | ~600â‚½ |
| **On-Demand** |||
| DataProc | Spark cluster | Pay-per-use | ~500â‚½ |
| **TOTAL** ||| **~24,000â‚½/month** |

---

## ğŸ¯ ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Kafka - Managed Service?

### âœ… ĞŸÑ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Managed Kafka:

1. **Reliability**
   - ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ±ÑĞºĞ°Ğ¿Ñ‹
   - Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ
   - Ğ ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

2. **Operations**
   - ĞĞµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ² K8s
   - ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ
   - Managed Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³

3. **Performance**
   - ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
   - Ğ“Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ€ĞµÑÑƒÑ€ÑÑ‹
   - Persistent storage

4. **Cost-effective**
   - s2.micro Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ°
   - HDD Ğ²Ğ¼ĞµÑÑ‚Ğ¾ SSD (Ğ´ĞµÑˆĞµĞ²Ğ»Ğµ)
   - ĞŸĞ»Ğ°Ñ‚Ğ¸Ñ‚Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ·Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

### âŒ ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ ĞĞ• Kafka Ğ² K8s:

- âŒ Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° StatefulSet
- âŒ Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ persistent volumes
- âŒ Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Zookeeper
- âŒ Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ°Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼
- âŒ Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸

---

## ğŸš€ Deployment

### 1. Terraform creates everything:

```bash
cd terraform
terraform init
terraform apply

# Creates:
# âœ… Managed Airflow
# âœ… Managed PostgreSQL
# âœ… Managed Kafka â­
# âœ… MLflow VM
# âœ… Grafana VM
# âœ… Kubernetes cluster
# âœ… S3 bucket
```

### 2. Deploy to Kubernetes:

```bash
# Configure kubectl
yc managed-kubernetes cluster get-credentials <cluster-id> --external --force

# Deploy applications
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/redis/
kubectl apply -f k8s/inference-api/
kubectl apply -f k8s/ml-workers/

# Note: Kafka is NOT deployed to K8s!
# Workers connect to Managed Kafka via external endpoint
```

### 3. Verify connections:

```bash
# Test Managed Kafka from K8s
kubectl run kafka-test --rm -it --image=confluentinc/cp-kafka:7.5.0 -- \
  kafka-console-producer \
  --bootstrap-server rc1a-mjs21l34cb7dh25g.mdb.yandexcloud.net:9091 \
  --topic fish-classification-requests \
  --producer-property security.protocol=SASL_SSL \
  --producer-property sasl.mechanism=SCRAM-SHA-512 \
  --producer-property sasl.jaas.config='org.apache.kafka.common.security.scram.ScramLoginModule required username="kafka_user" password="<password>";'
```

---

## ğŸ“‹ Summary

### Ğ’ KUBERNETES Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ğ¾:
- âœ… Inference API (FastAPI) - 3-20 pods
- âœ… ML Workers (Kafka consumers) - 2-10 pods
- âœ… Redis (caching) - 1 pod
- âœ… Monitoring (optional) - Prometheus, Node exporters

### Ğ’ MANAGED SERVICES Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ğ¾:
- âœ… Airflow - Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ
- âœ… PostgreSQL - Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
- âœ… **Kafka** â­ - **message queue**
- âœ… MLflow (VM) - tracking
- âœ… Grafana (VM) - Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³
- âœ… DataProc - training (on-demand)
- âœ… S3 - Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ

### Kafka Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ· K8s:
```python
from kafka import KafkaProducer

producer = KafkaProducer(
    bootstrap_servers='rc1a-mjs21l34cb7dh25g.mdb.yandexcloud.net:9091',
    security_protocol='SASL_SSL',
    sasl_mechanism='SCRAM-SHA-512',
    sasl_plain_username='kafka_user',
    sasl_plain_password='<password>',
    ssl_check_hostname=True
)

producer.send('fish-classification-requests', b'{"image_url": "..."}')
```

---

**Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾:** 2025-10-07  
**Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:** âœ… Production Ready  
**Kafka:** Managed Service (Ğ½Ğµ Ğ² K8s!)
