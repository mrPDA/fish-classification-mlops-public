"""
–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π PySpark —Å–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã
"""
import os
import sys
import subprocess

# –î–æ–±–∞–≤–ª—è–µ–º ~/.local –≤ PYTHONPATH –ü–ï–†–ï–î –≤—Å–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–º
local_site = os.path.expanduser('~/.local/lib/python3.8/site-packages')
if os.path.exists(local_site) and local_site not in sys.path:
    sys.path.insert(0, local_site)

# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–∞–∫–µ—Ç—ã –∏–∑ conda
conda_site = '/opt/conda/lib/python3.8/site-packages'
if conda_site not in sys.path:
    sys.path.insert(1, conda_site)

print("üîß Python environment setup complete")
print(f"   sys.path[0] = {sys.path[0]}")
print(f"   sys.path[1] = {sys.path[1]}")

# –ö–†–ò–¢–ò–ß–ù–û: –°–Ω–∞—á–∞–ª–∞ –æ–±–Ω–æ–≤–ª—è–µ–º NumPy –¥–æ –≤–µ—Ä—Å–∏–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–π —Å TensorFlow
print("üì¶ Upgrading NumPy for TensorFlow compatibility...")
subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--user', '--upgrade', 'numpy==1.24.3'])
if local_site not in sys.path:
    sys.path.insert(0, local_site)

# –¢–µ–ø–µ—Ä—å –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º NumPy –ü–û–°–õ–ï –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
import argparse
import numpy as np
import boto3
from PIL import Image
from pyspark.sql import SparkSession
from datetime import datetime
import io

print(f"‚úÖ NumPy: {np.__version__}")
print(f"‚úÖ Boto3: {boto3.__version__}")
print("‚úÖ Pillow: OK")

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º TensorFlow –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
try:
    import tensorflow as tf
    print(f"‚úÖ TensorFlow: {tf.__version__}")
except ImportError:
    print("üì¶ Installing TensorFlow...")
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--user', 'tensorflow==2.13.0'])
    # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º sys.path –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
    if local_site not in sys.path:
        sys.path.insert(0, local_site)
    import tensorflow as tf
    print(f"‚úÖ TensorFlow installed: {tf.__version__}")

try:
    import mlflow
    print(f"‚úÖ MLflow: {mlflow.__version__}")
except ImportError:
    print("üì¶ Installing MLflow...")
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--user', 'mlflow==2.9.2'])
    # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º sys.path –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
    if local_site not in sys.path:
        sys.path.insert(0, local_site)
    import mlflow
    print(f"‚úÖ MLflow installed: {mlflow.__version__}")

# Parse arguments
parser = argparse.ArgumentParser()
parser.add_argument('--s3-endpoint', required=True)
parser.add_argument('--s3-bucket', required=True)
parser.add_argument('--s3-access-key', required=True)
parser.add_argument('--s3-secret-key', required=True)
parser.add_argument('--mlflow-tracking-uri', required=True)
parser.add_argument('--mlflow-experiment', required=True)
parser.add_argument('--num-classes', type=int, default=9)
parser.add_argument('--image-size', type=int, default=224)
parser.add_argument('--batch-size', type=int, default=32)
parser.add_argument('--epochs', type=int, default=10)
parser.add_argument('--learning-rate', type=float, default=0.001)
args = parser.parse_args()

# Setup S3 and MLflow
os.environ['AWS_ACCESS_KEY_ID'] = args.s3_access_key
os.environ['AWS_SECRET_ACCESS_KEY'] = args.s3_secret_key
os.environ['MLFLOW_S3_ENDPOINT_URL'] = args.s3_endpoint

# –Ø–≤–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º boto3 default session –¥–ª—è MLflow
boto3.setup_default_session(
    aws_access_key_id=args.s3_access_key,
    aws_secret_access_key=args.s3_secret_key,
    region_name='ru-central1'
)

mlflow.set_tracking_uri(args.mlflow_tracking_uri)
mlflow.set_experiment(args.mlflow_experiment)

print("üöÄ Starting Spark...")
spark = SparkSession.builder.appName("FishClassificationTraining").getOrCreate()

# Load data from S3
print(f"üì• Loading dataset from S3: {args.s3_bucket}")
s3 = boto3.client(
    's3',
    endpoint_url=args.s3_endpoint,
    aws_access_key_id=args.s3_access_key,
    aws_secret_access_key=args.s3_secret_key
)

# List classes
fish_classes = []
result = s3.list_objects_v2(Bucket=args.s3_bucket, Prefix='datasets/', Delimiter='/')
if 'CommonPrefixes' in result:
    for prefix in result['CommonPrefixes']:
        class_name = prefix['Prefix'].split('/')[-2]
        if class_name and class_name not in ['datasets', '.DS_Store']:
            fish_classes.append(class_name)

print(f"‚úÖ Found {len(fish_classes)} fish classes: {fish_classes[:5]}...")

# Load images
def load_images_from_s3(bucket, prefix, limit=50):
    images = []
    labels = []
    
    for class_idx, class_name in enumerate(fish_classes):
        class_prefix = f"{prefix}{class_name}/"
        print(f"   Loading class {class_idx + 1}/{len(fish_classes)}: {class_name}")
        
        response = s3.list_objects_v2(Bucket=bucket, Prefix=class_prefix, MaxKeys=limit)
        if 'Contents' not in response:
            continue
        
        for obj in response['Contents']:
            key = obj['Key']
            if not key.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue
            
            try:
                img_obj = s3.get_object(Bucket=bucket, Key=key)
                img_data = img_obj['Body'].read()
                img = Image.open(io.BytesIO(img_data)).convert('RGB')
                img = img.resize((args.image_size, args.image_size))
                img_array = tf.keras.preprocessing.image.img_to_array(img)
                img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)
                images.append(img_array)
                labels.append(class_idx)
            except Exception as e:
                print(f"      ‚ö†Ô∏è  Failed to load {key}: {e}")
                continue
    
    return np.array(images), np.array(labels)

X, y = load_images_from_s3(args.s3_bucket, 'datasets/', limit=50)
print(f"‚úÖ Loaded {len(X)} images, shape: {X.shape}")

# Split
from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print(f"‚úÖ Train: {len(X_train)}, Val: {len(X_val)}")

# Build model
print("üèóÔ∏è  Building model...")
base_model = tf.keras.applications.MobileNetV2(
    input_shape=(args.image_size, args.image_size, 3),
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False

model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(len(fish_classes), activation='softmax')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=args.learning_rate),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print(f"‚úÖ Model built: {model.count_params():,} parameters")

# Train with MLflow
print("üéì Training...")
with mlflow.start_run(run_name=f"fish_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
    mlflow.log_param("base_model", "MobileNetV2")
    mlflow.log_param("epochs", args.epochs)
    mlflow.log_param("batch_size", args.batch_size)
    mlflow.log_param("learning_rate", args.learning_rate)
    mlflow.log_param("num_classes", len(fish_classes))
    mlflow.log_param("train_samples", len(X_train))
    mlflow.log_param("val_samples", len(X_val))
    
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=args.epochs,
        batch_size=args.batch_size,
        verbose=1
    )
    
    for epoch in range(args.epochs):
        mlflow.log_metric("train_loss", history.history['loss'][epoch], step=epoch)
        mlflow.log_metric("train_accuracy", history.history['accuracy'][epoch], step=epoch)
        mlflow.log_metric("val_loss", history.history['val_loss'][epoch], step=epoch)
        mlflow.log_metric("val_accuracy", history.history['val_accuracy'][epoch], step=epoch)
    
    final_train_acc = history.history['accuracy'][-1]
    final_val_acc = history.history['val_accuracy'][-1]
    
    print(f"\n‚úÖ Training complete!")
    print(f"   Final train accuracy: {final_train_acc:.4f}")
    print(f"   Final val accuracy: {final_val_acc:.4f}")
    
    mlflow.tensorflow.log_model(model, "model")
    mlflow.log_dict({str(i): name for i, name in enumerate(fish_classes)}, "class_names.json")
    
    print(f"‚úÖ Model logged to MLflow: run_id={mlflow.active_run().info.run_id}")
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –≤ Model Registry –∏ –ø–µ—Ä–µ—Ö–æ–¥ –≤ Production
    print("\n" + "=" * 80)
    print("üì¶ Registering model in MLflow Model Registry...")
    print("=" * 80)
    
    try:
        from mlflow.tracking import MlflowClient
        
        client = MlflowClient()
        model_name = "fish-classifier-efficientnet-b4"
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º run
        run_id = mlflow.active_run().info.run_id
        model_uri = f"runs:/{run_id}/model"
        
        print(f"   Model URI: {model_uri}")
        print(f"   Model Name: {model_name}")
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏
        model_version = mlflow.register_model(
            model_uri=model_uri,
            name=model_name,
            tags={
                "accuracy": f"{final_train_acc:.4f}",
                "val_accuracy": f"{final_val_acc:.4f}",
                "framework": "tensorflow",
                "architecture": "mobilenet-v2",
                "training_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "auto_registered": "true"
            }
        )
        
        print(f"‚úÖ Model registered: {model_name}, version: {model_version.version}")
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ Production
        # –°–Ω–∞—á–∞–ª–∞ –∞—Ä—Ö–∏–≤–∏—Ä—É–µ–º –≤—Å–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ Production –º–æ–¥–µ–ª–∏
        try:
            production_models = client.get_latest_versions(model_name, stages=["Production"])
            for prod_model in production_models:
                print(f"   Archiving previous Production model version {prod_model.version}")
                client.transition_model_version_stage(
                    name=model_name,
                    version=prod_model.version,
                    stage="Archived",
                    archive_existing_versions=False
                )
        except Exception as e:
            print(f"   No previous Production models to archive: {e}")
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –≤ Production
        client.transition_model_version_stage(
            name=model_name,
            version=model_version.version,
            stage="Production",
            archive_existing_versions=True
        )
        
        print(f"‚úÖ Model version {model_version.version} transitioned to Production stage")
        print(f"   Model Registry URL: {mlflow_uri}/#/models/{model_name}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Warning: Failed to register model in Model Registry: {e}")
        print("   Model artifacts are still logged in MLflow run")
    
    mlflow.end_run()

spark.stop()
print("\n" + "=" * 80)
print("‚úÖ Training completed successfully!")
print("üéØ Model automatically registered and deployed to Production!")
print("=" * 80)
